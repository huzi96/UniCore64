From d25d5f075ee2e002e5b0ee5cc5839acad1da1295 Mon Sep 17 00:00:00 2001
From: Chang Huaixin <changhuaixin@mprc.pku.edu.cn>
Date: Wed, 19 Dec 2012 20:52:31 +0800
Subject: [PATCH 506/641] unicore64: Modify use of llw and scw instructions

Signed-off-by: Chang Huaixin <changhuaixin@mprc.pku.edu.cn>
---
 arch/unicore64/include/asm/atomic.h   |    8 ++++----
 arch/unicore64/include/asm/cmpxchg.h  |    8 ++++----
 arch/unicore64/include/asm/spinlock.h |   20 ++++++++++----------
 3 files changed, 18 insertions(+), 18 deletions(-)

diff --git a/arch/unicore64/include/asm/atomic.h b/arch/unicore64/include/asm/atomic.h
index 4ccdbf7..78be049 100644
--- a/arch/unicore64/include/asm/atomic.h
+++ b/arch/unicore64/include/asm/atomic.h
@@ -13,10 +13,10 @@
 		int result;						\
 		smp_mb();						\
 		__asm__ __volatile__(					\
-			"1:	llw		%0, [%2+], #0\n"	\
+			"1:	llw		%0, [%2]\n"		\
 			"	add		%0, %0, %3\n"		\
 			"	mov		%1, %0\n"		\
-			"	scw		%1, [%2+], #0\n"	\
+			"	scw		%1, [%2]\n"		\
 			"	cmpsub.a	%1, #0\n"		\
 			"	beq		1b"			\
 			: "=&r" (result), "=&r" (tmp)			\
@@ -34,10 +34,10 @@
 		int result;						\
 		smp_mb();						\
 		__asm__ __volatile__(					\
-			"1:	llw		%0, [%2+], #0\n"	\
+			"1:	llw		%0, [%2]\n"		\
 			"	sub		%0, %0, %3\n"		\
 			"	mov		%1, %0\n"		\
-			"	scw		%1, [%2+], #0\n"	\
+			"	scw		%1, [%2]\n"		\
 			"	cmpsub.a	%1, #0\n"		\
 			"	beq		1b"			\
 			: "=&r" (result), "=&r" (tmp)			\
diff --git a/arch/unicore64/include/asm/cmpxchg.h b/arch/unicore64/include/asm/cmpxchg.h
index 125f3ba..98c3f4f 100644
--- a/arch/unicore64/include/asm/cmpxchg.h
+++ b/arch/unicore64/include/asm/cmpxchg.h
@@ -22,11 +22,11 @@ static inline unsigned long __cmpxchg(volatile void *ptr, unsigned long old,
 	switch (size) {
 	case 4:
 		__asm__ __volatile__(
-			"1:	llw		%0, [%1+], #0\n"
+			"1:	llw		%0, [%1]\n"
 			"	cmpsub.a	%0, %2\n"
 			"	bne		2f\n"
 			"	mov		%0, %3\n"
-			"	scw		%0, [%1+], #0\n"
+			"	scw		%0, [%1]\n"
 			"	cmpsub.a	%0, #0\n"
 			"	beq		1b\n"
 			"	mov		%0, %2\n"
@@ -37,11 +37,11 @@ static inline unsigned long __cmpxchg(volatile void *ptr, unsigned long old,
 		break;
 	case 8:
 		__asm__ __volatile__(
-			"1:	lld		%0, [%1+], #0\n"
+			"1:	lld		%0, [%1]\n"
 			"	dcmpsub.a	%0, %2\n"
 			"	bne		2f\n"
 			"	dmov		%0, %3\n"
-			"	scd		%0, [%1+], #0\n"
+			"	scd		%0, [%1]\n"
 			"	dcmpsub.a	%0, #0\n"
 			"	beq		1b\n"
 			"	dmov		%0, %2\n"
diff --git a/arch/unicore64/include/asm/spinlock.h b/arch/unicore64/include/asm/spinlock.h
index 5e81072..70bbb6e 100644
--- a/arch/unicore64/include/asm/spinlock.h
+++ b/arch/unicore64/include/asm/spinlock.h
@@ -25,11 +25,11 @@ static inline void arch_spin_lock(arch_spinlock_t *lock)
 	u32 tmp;
 
 	__asm__ __volatile__(
-		"1:	llw		%0, [%1+], #0\n"
+		"1:	llw		%0, [%1]\n"
 		"	cmpsub.a	%0, #0\n"
 		"	bne		1b\n"
 		"	mov		%0, %2\n"
-		"	scw		%0, [%1+], #0\n"
+		"	scw		%0, [%1]\n"
 		"	cmpsub.a	%0, #0\n"
 		"	beq		1b"
 		: "=&r" (tmp)
@@ -51,12 +51,12 @@ static inline int arch_spin_trylock(arch_spinlock_t *lock)
 	u32 tmp;
 
 	__asm__ __volatile__(
-		"	llw		%0, [%1+], #0\n"
+		"	llw		%0, [%1]\n"
 		"	cmpsub.a	%0, #0\n"
 		"	cmovne		%0, #0\n"
 		"	bne		1f\n"
 		"	mov		%0, %2\n"
-		"	scw		%0, [%1+], #0\n"
+		"	scw		%0, [%1]\n"
 		"1:"
 		: "=&r" (tmp)
 		: "r" (&lock->lock), "r" (LOCK_TOKEN)
@@ -73,11 +73,11 @@ static inline void arch_read_lock(arch_rwlock_t *rw)
 	u32 tmp;
 
 	__asm__ __volatile__(
-		"1:	llw		%0, [%1+], #0\n"
+		"1:	llw		%0, [%1]\n"
 		"	cmpsub.a	%0, #0\n"
 		"	bsl		1b\n"
 		"	add		%0, %0, #1\n"
-		"	scw		%0, [%1+], #0\n"
+		"	scw		%0, [%1]\n"
 		"	cmpsub.a	%0, #0\n"
 		"	beq		1b"
 		: "=&r" (tmp)
@@ -94,9 +94,9 @@ static inline void arch_read_unlock(arch_rwlock_t *rw)
 	smp_mb();
 
 	__asm__ __volatile__(
-		"1:	llw		%0, [%1+], #0\n"
+		"1:	llw		%0, [%1]\n"
 		"	sub		%0, %0, #1\n"
-		"	scw		%0, [%1+], #0\n"
+		"	scw		%0, [%1]\n"
 		"	cmpsub.a	%0, #0\n"
 		"	beq		1b"
 		: "=&r" (tmp)
@@ -119,11 +119,11 @@ static inline void arch_write_lock(arch_rwlock_t *rw)
 	u32 tmp;
 
 	__asm__ __volatile__(
-		"1:	llw		%0, [%1+], #0\n"
+		"1:	llw		%0, [%1]\n"
 		"	cmpsub.a	%0, #0\n"
 		"	bne		1b\n"
 		"	mov		%0, %2\n"
-		"	scw		%0, [%1+], #0\n"
+		"	scw		%0, [%1]\n"
 		"	cmpsub.a	%0, #0\n"
 		"	beq		1b"
 		: "=&r" (tmp)
-- 
1.7.9.5

